{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0. Package setting\n",
    "The way to do this is to manually check how to install the packages in your environment. \n",
    "this worked on collab but I installed the packages manually in my machine, the porcedure to get them will likely ghe different depending on your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPcbliDiKsAq"
   },
   "outputs": [],
   "source": [
    "#  Install necessary libraries\n",
    "!pip install transformers torch torchaudio pyaudio pydub huggingface_hub librosa soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfSwRpnIMZaE"
   },
   "outputs": [],
   "source": [
    "# I seems that some libraries are needed in order to install pyaudio.\n",
    "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
    "!pip install PyAudio pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "DZSBhqhuK44t"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor, WhisperFeatureExtractor, WhisperTokenizer\n",
    "import pyaudio\n",
    "import wave\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import Audio\n",
    "import os\n",
    "from scipy.signal import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part seems necessary for later\n",
    "\n",
    "import evaluate\n",
    "from jiwer import cer\n",
    "\n",
    "def down_sample_audio(audio_original, original_sample_rate):\n",
    "    target_sample_rate = 16000\n",
    "\n",
    "    # Calculate the number of samples for the target sample rate\n",
    "    num_samples = int(len(audio_original) * target_sample_rate / original_sample_rate)\n",
    "\n",
    "    # Resample the audio array to the target sample rate\n",
    "    downsampled_audio = resample(audio_original, num_samples)\n",
    "\n",
    "    return downsampled_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wikY7LTtLAEh"
   },
   "source": [
    "## Part 1: Loading model and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load every part of the small model separately\n",
    "\n",
    "MODEL_REPO = \"SchindleriaPraematurus/whisper-tiny-gn-finetuned\" # Your repository\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "SMALL_TOKENIZER_COMMIT_HASH = \"6cd67df1b6923465434cee5bb80aadfe7a8d74ab\"  # Commit for \"Upload tokenizer\"\n",
    "SMALL_FEATURE_EXTRACTOR_COMMIT_HASH = \"a7f430d0d46753348597fb241734d341c48fc69b\" # Commit for \"Upload feature_extractor\"\n",
    "SMALL_MODEL_COMMIT_HASH = \"06294d5a001f1f32290e98cf9a4a6006f1fc394a\" # Commit for \"Upload fine-tuned Whisper-small\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movin to CPU because I ran our of ram LOL (Change this)\n",
    "DEVICE='cpu' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "B13NiPIZK6ty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load 'small' version components from specific commits:\n",
      " - Tokenizer commit: 6cd67df1b6923465434cee5bb80aadfe7a8d74ab\n",
      " - Feature Extractor commit: a7f430d0d46753348597fb241734d341c48fc69b\n",
      " - Model commit: 06294d5a001f1f32290e98cf9a4a6006f1fc394a\n",
      "\n",
      "Loading small tokenizer from revision: 6cd67df1b6923465434cee5bb80aadfe7a8d74ab...\n",
      "Successfully loaded 'small' tokenizer.\n",
      "\n",
      "Loading small feature extractor from revision: a7f430d0d46753348597fb241734d341c48fc69b...\n",
      "Successfully loaded 'small' feature extractor.\n",
      "\n",
      "Loading small model from revision: 06294d5a001f1f32290e98cf9a4a6006f1fc394a...\n",
      "Successfully loaded 'small' model.\n",
      "\n",
      "Successfully created 'small' WhisperProcessor manually.\n",
      "\n",
      "Successfully prepared 'small' model (from multiple commits) for comparison.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"Attempting to load 'small' version components from specific commits:\")\n",
    "print(f\" - Tokenizer commit: {SMALL_TOKENIZER_COMMIT_HASH}\")\n",
    "print(f\" - Feature Extractor commit: {SMALL_FEATURE_EXTRACTOR_COMMIT_HASH}\")\n",
    "print(f\" - Model commit: {SMALL_MODEL_COMMIT_HASH}\")\n",
    "\n",
    "tokenizer_small = None\n",
    "feature_extractor_small = None\n",
    "model_small = None\n",
    "processor_small = None\n",
    "\n",
    "try:\n",
    "    # Load Tokenizer\n",
    "    # These settings are usually saved in tokenizer_config.json.\n",
    "    print(f\"\\nLoading small tokenizer from revision: {SMALL_TOKENIZER_COMMIT_HASH}...\")\n",
    "    tokenizer_small = WhisperTokenizer.from_pretrained(\n",
    "        MODEL_REPO,\n",
    "        revision=SMALL_TOKENIZER_COMMIT_HASH\n",
    "    )\n",
    "    print(\"Successfully loaded 'small' tokenizer.\")\n",
    "\n",
    "    # Load Feature Extractor\n",
    "    print(f\"\\nLoading small feature extractor from revision: {SMALL_FEATURE_EXTRACTOR_COMMIT_HASH}...\")\n",
    "    feature_extractor_small = WhisperFeatureExtractor.from_pretrained(\n",
    "        MODEL_REPO,\n",
    "        revision=SMALL_FEATURE_EXTRACTOR_COMMIT_HASH\n",
    "    )\n",
    "    print(\"Successfully loaded 'small' feature extractor.\")\n",
    "\n",
    "    # Load Model\n",
    "    print(f\"\\nLoading small model from revision: {SMALL_MODEL_COMMIT_HASH}...\")\n",
    "    model_small = WhisperForConditionalGeneration.from_pretrained(\n",
    "        MODEL_REPO,\n",
    "        revision=SMALL_MODEL_COMMIT_HASH\n",
    "    ).to(DEVICE)\n",
    "    model_small.eval()\n",
    "    print(\"Successfully loaded 'small' model.\")\n",
    "\n",
    "    # Manually create the WhisperProcessor instance\n",
    "    if tokenizer_small and feature_extractor_small:\n",
    "        processor_small = WhisperProcessor(feature_extractor=feature_extractor_small, tokenizer=tokenizer_small)\n",
    "        print(\"\\nSuccessfully created 'small' WhisperProcessor manually.\")\n",
    "    else:\n",
    "        print(\"\\nCould not create 'small' processor because tokenizer or feature extractor failed to load.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during loading of 'small' components: {e}\")\n",
    "    print(\"Please double-check the following:\")\n",
    "    print(\"1. All three commit hashes are correct and point to the respective uploads for the 'small' version.\")\n",
    "    print(f\"2. The tokenizer files (vocab.json, tokenizer_config.json, etc.) are indeed present at commit {SMALL_TOKENIZER_COMMIT_HASH}.\")\n",
    "    print(f\"3. The feature extractor's preprocessor_config.json is present at commit {SMALL_FEATURE_EXTRACTOR_COMMIT_HASH}.\")\n",
    "    print(f\"4. The model files (pytorch_model.bin, config.json) are present at commit {SMALL_MODEL_COMMIT_HASH}.\")\n",
    "\n",
    "if model_small and processor_small:\n",
    "    print(f\"\\nSuccessfully prepared 'small' model (from multiple commits) for comparison.\")\n",
    "    # You can now use model_small and processor_small for predictions\n",
    "else:\n",
    "    print(f\"\\nFailed to fully load the 'small' model and processor. Check error messages above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TVkM0VuNJLN"
   },
   "source": [
    "## Part 2. Getting audio as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "bLd2bA2FNjOa",
    "outputId": "a38711c5-67e2-43a3-9562-a275e926cdf1"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Record audio for a fixed duration\n",
    "FORMAT = pyaudio.paInt16  # Audio format (16-bit PCM)\n",
    "CHANNELS = 1              # Number of audio channels (1 for mono, 2 for stereo)\n",
    "RATE = 16000              # Sample rate (Whisper expects 16kHz)\n",
    "CHUNK = 1024              # Number of frames per buffer\n",
    "RECORD_SECONDS = 5        # Duration of recording in seconds\n",
    "WAV_FILENAME = \"recorded_audio.wav\"\n",
    "MP3_FILENAME = \"recorded_audio.mp3\"\n",
    "\n",
    "audio = pyaudio.PyAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n",
      "Audio saved as recorded_audio.wav\n",
      "Converted to recorded_audio.mp3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Start Recording\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Recording...\")\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"Finished recording.\")\n",
    "\n",
    "# Stop Recording\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "# Save the recorded data as a WAV file\n",
    "wf = wave.open(WAV_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "\n",
    "print(f\"Audio saved as {WAV_FILENAME}\")\n",
    "\n",
    "# Convert WAV to MP3 using pydub\n",
    "try:\n",
    "    sound = AudioSegment.from_wav(WAV_FILENAME)\n",
    "    sound.export(MP3_FILENAME, format=\"mp3\")\n",
    "    print(f\"Converted to {MP3_FILENAME}\")\n",
    "    os.remove(WAV_FILENAME) # Optional: remove the intermediate WAV file\n",
    "    # Display the audio player in the notebook\n",
    "    display(Audio(MP3_FILENAME))\n",
    "except Exception as e:\n",
    "    print(f\"Could not convert to MP3. Make sure ffmpeg is installed and in your PATH. Error: {e}\")\n",
    "    print(\"You can still use the WAV file for prediction if MP3 conversion fails, but ensure your prediction block loads the correct file type.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "Vff6cvX_NJSf",
    "outputId": "0febfea5-cbbd-4ef8-df4a-374fb233fe68"
   },
   "outputs": [],
   "source": [
    "# Cell 5: Record audio (stop with Enter key in console - more for script, but can work)\n",
    "# This method will record until you press Enter in the console where Jupyter is running.\n",
    "# Note: In some environments (like Colab without specific widgets), direct key press detection is hard.\n",
    "# A simpler alternative is just a longer fixed duration.\n",
    "\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000 # Whisper expects 16kHz\n",
    "CHUNK = 1024\n",
    "WAV_FILENAME_MANUAL = \"recorded_audio_manual.wav\"\n",
    "MP3_FILENAME_MANUAL = \"recorded_audio_manual.mp3\"\n",
    "\n",
    "audio = pyaudio.PyAudio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Recording... Press Enter in the console running Jupyter to stop.\")\n",
    "frames = []\n",
    "# This input() will block, so recording happens while it waits.\n",
    "# This isn't a perfect \"stop recording on keypress\" but a simple way to gate it.\n",
    "# For true keypress stop, you'd need a more complex GUI or threading.\n",
    "try:\n",
    "    while True: # A loop to simulate continuous recording until input\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "        # This is a crude way to check for input without blocking read too much\n",
    "        # It's not ideal. A better way is to record fixed long duration or use threads.\n",
    "        # For this example, let's make it simpler: Record for a max duration or until input.\n",
    "        # The input() below is the primary stop.\n",
    "except KeyboardInterrupt: # If you press Ctrl+C in console\n",
    "    print(\"Recording stopped by user.\")\n",
    "except Exception as e:\n",
    "    pass # Handle other potential stream errors\n",
    "\n",
    "# The following is a simpler approach for notebooks:\n",
    "# Ask user to press enter, then record for a few seconds.\n",
    "# Or, just use a fixed duration like Method 1.\n",
    "\n",
    "# Let's refine Method 2 for a notebook: record after user hits enter.\n",
    "print(\"Prepare to record. Press Enter to start recording for 10 seconds.\")\n",
    "input() # Wait for user to press Enter\n",
    "\n",
    "print(\"Recording for 10 seconds...\")\n",
    "frames = []\n",
    "for i in range(0, int(RATE / CHUNK * 10)): # Record for 10 seconds\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "print(\"Finished recording.\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "wf = wave.open(WAV_FILENAME_MANUAL, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "print(f\"Audio saved as {WAV_FILENAME_MANUAL}\")\n",
    "\n",
    "try:\n",
    "    sound = AudioSegment.from_wav(WAV_FILENAME_MANUAL)\n",
    "    sound.export(MP3_FILENAME_MANUAL, format=\"mp3\")\n",
    "    print(f\"Converted to {MP3_FILENAME_MANUAL}\")\n",
    "    os.remove(WAV_FILENAME_MANUAL)\n",
    "    display(Audio(MP3_FILENAME_MANUAL))\n",
    "except Exception as e:\n",
    "    print(f\"Could not convert to MP3: {e}. Using WAV.\")\n",
    "    MP3_FILENAME_MANUAL = WAV_FILENAME_MANUAL # Fallback to WAV if MP3 fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3pYHOEFNvI5"
   },
   "source": [
    "## Part 3. Geting predictions with new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    feature_extractor=feature_extractor,\n",
    "    chunk_length_s=30,     # 30s chunks\n",
    "    stride_length_s=10,    # 10s overlap\n",
    "    device='cuda',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"recorded_audio.mp3\"\n",
    "result = pipe(file_path)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RSKvi0vN3nz"
   },
   "source": [
    "## Part 4. Comparing model sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "qtfc-B0uN3t2"
   },
   "outputs": [],
   "source": [
    "# Cell 7: Load the 'tiny' version components using their specific commit hashes\n",
    "\n",
    "MODEL_REPO = \"SchindleriaPraematurus/whisper-tiny-gn-finetuned\" # Your repository\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "TINY_TOKENIZER_COMMIT_HASH = \"5d8e8d409cb195deb958c6733939dae432db2a52\"  # Commit for \"Upload tokenizer\"\n",
    "TINY_FEATURE_EXTRACTOR_COMMIT_HASH = \"612f9f357ea4677f69fcfae2ffaa4c55534a3ac2\" # Commit for \"Upload feature_extractor\"\n",
    "TINY_MODEL_COMMIT_HASH = \"712fa109774ac1a772be3c29b718785afa865a9e\" # Commit for \"Upload fine-tuned Whisper-tiny\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load 'tiny' version components from specific commits:\n",
      " - Tokenizer commit: 5d8e8d409cb195deb958c6733939dae432db2a52\n",
      " - Feature Extractor commit: 612f9f357ea4677f69fcfae2ffaa4c55534a3ac2\n",
      " - Model commit: 712fa109774ac1a772be3c29b718785afa865a9e\n",
      "\n",
      "Loading tiny tokenizer from revision: 5d8e8d409cb195deb958c6733939dae432db2a52...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244dca9f52874ac3917424f3c1c43842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07b7ef1d6774a45824d81d13918fb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecb4179364042318a0cb87b0c161e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561e6f198dcb41cda8f939f116b21d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1706dc3c86eb4615a936609386d383b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb716e457c54b00abbd231ccfebfc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'tiny' tokenizer.\n",
      "\n",
      "Loading tiny feature extractor from revision: 612f9f357ea4677f69fcfae2ffaa4c55534a3ac2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42dfd7317ef84d889ddf31a2efa2fc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/356 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'tiny' feature extractor.\n",
      "\n",
      "Loading tiny model from revision: 712fa109774ac1a772be3c29b718785afa865a9e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1b6106d10046169c344ac674598f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df137dda655547bb89c1fe75e73c9a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf20fd5cb964871bf4a68567f3ecd4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'tiny' model.\n",
      "\n",
      "Successfully created 'tiny' WhisperProcessor manually.\n",
      "\n",
      "Successfully prepared 'tiny' model (from multiple commits) for comparison.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"Attempting to load 'tiny' version components from specific commits:\")\n",
    "print(f\" - Tokenizer commit: {TINY_TOKENIZER_COMMIT_HASH}\")\n",
    "print(f\" - Feature Extractor commit: {TINY_FEATURE_EXTRACTOR_COMMIT_HASH}\")\n",
    "print(f\" - Model commit: {TINY_MODEL_COMMIT_HASH}\")\n",
    "\n",
    "tokenizer_tiny = None\n",
    "feature_extractor_tiny = None\n",
    "model_tiny = None\n",
    "processor_tiny = None\n",
    "\n",
    "try:\n",
    "    # Load Tokenizer\n",
    "    # Your training script loaded the initial tokenizer with language=\"spanish\", task=\"transcribe\".\n",
    "    # These settings are usually saved in tokenizer_config.json.\n",
    "    # Try loading without explicit language/task first, as it should use the saved config.\n",
    "    print(f\"\\nLoading tiny tokenizer from revision: {TINY_TOKENIZER_COMMIT_HASH}...\")\n",
    "    tokenizer_tiny = WhisperTokenizer.from_pretrained(\n",
    "        MODEL_REPO,\n",
    "        revision=TINY_TOKENIZER_COMMIT_HASH\n",
    "    )\n",
    "    print(\"Successfully loaded 'tiny' tokenizer.\")\n",
    "\n",
    "    # Load Feature Extractor\n",
    "    print(f\"\\nLoading tiny feature extractor from revision: {TINY_FEATURE_EXTRACTOR_COMMIT_HASH}...\")\n",
    "    feature_extractor_tiny = WhisperFeatureExtractor.from_pretrained(\n",
    "        MODEL_REPO,\n",
    "        revision=TINY_FEATURE_EXTRACTOR_COMMIT_HASH\n",
    "    )\n",
    "    print(\"Successfully loaded 'tiny' feature extractor.\")\n",
    "\n",
    "    # Load Model\n",
    "    print(f\"\\nLoading tiny model from revision: {TINY_MODEL_COMMIT_HASH}...\")\n",
    "    model_tiny = WhisperForConditionalGeneration.from_pretrained(\n",
    "        MODEL_REPO,\n",
    "        revision=TINY_MODEL_COMMIT_HASH\n",
    "    ).to(DEVICE)\n",
    "    model_tiny.eval()\n",
    "    print(\"Successfully loaded 'tiny' model.\")\n",
    "\n",
    "    # Manually create the WhisperProcessor instance\n",
    "    if tokenizer_tiny and feature_extractor_tiny:\n",
    "        processor_tiny = WhisperProcessor(feature_extractor=feature_extractor_tiny, tokenizer=tokenizer_tiny)\n",
    "        print(\"\\nSuccessfully created 'tiny' WhisperProcessor manually.\")\n",
    "    else:\n",
    "        print(\"\\nCould not create 'tiny' processor because tokenizer or feature extractor failed to load.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during loading of 'tiny' components: {e}\")\n",
    "    print(\"Please double-check the following:\")\n",
    "    print(\"1. All three commit hashes are correct and point to the respective uploads for the 'tiny' version.\")\n",
    "    print(f\"2. The tokenizer files (vocab.json, tokenizer_config.json, etc.) are indeed present at commit {TINY_TOKENIZER_COMMIT_HASH}.\")\n",
    "    print(f\"3. The feature extractor's preprocessor_config.json is present at commit {TINY_FEATURE_EXTRACTOR_COMMIT_HASH}.\")\n",
    "    print(f\"4. The model files (pytorch_model.bin, config.json) are present at commit {TINY_MODEL_COMMIT_HASH}.\")\n",
    "\n",
    "if model_tiny and processor_tiny:\n",
    "    print(f\"\\nSuccessfully prepared 'tiny' model (from multiple commits) for comparison.\")\n",
    "    # You can now use model_tiny and processor_tiny for predictions\n",
    "else:\n",
    "    print(f\"\\nFailed to fully load the 'tiny' model and processor. Check error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tiny.generation_config.forced_decoder_ids = None\n",
    "\n",
    "model_tiny.generation_config.language = \"spanish\"\n",
    "model_tiny.generation_config.task = \"transcribe\"\n",
    "\n",
    "\n",
    "gen_config_for_tiny = model_tiny.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------0------\n",
      "true : omba'apóva ñanduti iporãve hag̃ua \n",
      "pred : Omba'apóva ñanduti iporãve hag̃ua.\n",
      "\n",
      " \n",
      "-------1------\n",
      "true : Ñúme katu ynambu oĩva'ekue. \n",
      "pred : Ñome katu ymamboy'íva'ekue.\n",
      "\n",
      " \n",
      "-------2------\n",
      "true : Heta ára ndaje ohasa asy. \n",
      "pred : Heta ára ndaje ohasa'asy.\n",
      "\n",
      " \n",
      "-------3------\n",
      "true : ¡Pepracticavéke! \n",
      "pred : Peperatĩ kavéke.\n",
      "\n",
      " \n",
      "-------4------\n",
      "true : sa'íma oĩ ka'aguy \n",
      "pred : sa'íma oĩ ka'aguý\n",
      "\n",
      " \n",
      "-------5------\n",
      "true : ha ijykére mitãrusu roky \n",
      "pred : ha ijykére mitãrusu roky\n",
      "\n",
      " \n",
      "-------6------\n",
      "true : iporã umíva ojapokuaa \n",
      "pred : Iporã umíva ojapokuaa.\n",
      "\n",
      " \n",
      "-------7------\n",
      "true : Mitã ojapo'ỹva isy ha itúva ojeruréva chupekuéra. \n",
      "pred : Mitã ojapo'ỹva isy ha itúva ojerureva chupekuéra.\n",
      "\n",
      " \n",
      "-------8------\n",
      "true : Oiménepiko ojeráma \n",
      "pred : Oiméne piko ojeráma.\n",
      "\n",
      " \n",
      "-------9------\n",
      "true : Hetaitereíko ihénte la abuela \n",
      "pred : Hetaiterei ko'i hénte la abuela.\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "model_tiny.eval()\n",
    "\n",
    "\n",
    "test_data = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"gn\", split=\"test\")\n",
    "\n",
    "for idx in range(10):\n",
    "\n",
    "    target = test_data[idx]['sentence']\n",
    "    audio_original = test_data[idx]['audio']['array']\n",
    "    original_sample_rate = test_data[idx]['audio']['sampling_rate']\n",
    "\n",
    "    audio_16000 = down_sample_audio(audio_original, original_sample_rate)\n",
    "\n",
    "    input_feature = feature_extractor_tiny(raw_speech=audio_16000,\n",
    "                                    sampling_rate=16000,\n",
    "                                    return_tensors='pt').input_features\n",
    "\n",
    "    with torch.no_grad():\n",
    "        op = model_tiny.generate(input_feature.to('cuda'), generation_config=gen_config_for_tiny)\n",
    "\n",
    "\n",
    "    text_pred =  tokenizer_tiny.batch_decode(op,skip_special_tokens=True )[0]\n",
    "\n",
    "    print(f'-------{idx}------')\n",
    "    print(f'true : {target} \\npred : {text_pred}')\n",
    "    print('\\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small.generation_config.forced_decoder_ids = None\n",
    "\n",
    "model_small.generation_config.language = \"spanish\"\n",
    "model_small.generation_config.task = \"transcribe\"\n",
    "\n",
    "\n",
    "gen_config_for_small = model_small.generation_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------0------\n",
      "true : omba'apóva ñanduti iporãve hag̃ua \n",
      "pred : omba'apóva ñanduti iporãve hag̃ua\n",
      "\n",
      " \n",
      "-------1------\n",
      "true : Ñúme katu ynambu oĩva'ekue. \n",
      "pred : Ñúme katu ynambu oĩva'ekue.\n",
      "\n",
      " \n",
      "-------2------\n",
      "true : Heta ára ndaje ohasa asy. \n",
      "pred : Heta ára ndaje ohasa asy.\n",
      "\n",
      " \n",
      "-------3------\n",
      "true : ¡Pepracticavéke! \n",
      "pred : ¡Pepracticavéke!\n",
      "\n",
      " \n",
      "-------4------\n",
      "true : sa'íma oĩ ka'aguy \n",
      "pred : sa'íma oĩ ka'aguy\n",
      "\n",
      " \n",
      "-------5------\n",
      "true : ha ijykére mitãrusu roky \n",
      "pred : ha ijykére mitãrusu roky\n",
      "\n",
      " \n",
      "-------6------\n",
      "true : iporã umíva ojapokuaa \n",
      "pred : iporã umíva ojapokuaa\n",
      "\n",
      " \n",
      "-------7------\n",
      "true : Mitã ojapo'ỹva isy ha itúva ojeruréva chupekuéra. \n",
      "pred : Mitã ojapo'ỹva isy ha itúva ojeruréva chupekuéra.\n",
      "\n",
      " \n",
      "-------8------\n",
      "true : Oiménepiko ojeráma \n",
      "pred : Oiménepiko ojeráma\n",
      "\n",
      " \n",
      "-------9------\n",
      "true : Hetaitereíko ihénte la abuela \n",
      "pred : Hetaitereíko ihénte la abuela\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "model_small.eval()\n",
    "\n",
    "for idx in range(10):\n",
    "\n",
    "    target = test_data[idx]['sentence']\n",
    "    audio_original = test_data[idx]['audio']['array']\n",
    "    original_sample_rate = test_data[idx]['audio']['sampling_rate']\n",
    "\n",
    "    audio_16000 = down_sample_audio(audio_original, original_sample_rate)\n",
    "\n",
    "    input_feature = feature_extractor_small(raw_speech=audio_16000,\n",
    "                                    sampling_rate=16000,\n",
    "                                    return_tensors='pt').input_features\n",
    "\n",
    "    with torch.no_grad():\n",
    "        op = model_small.generate(input_feature.to('cpu'), generation_config=gen_config_for_small)\n",
    "\n",
    "\n",
    "    text_pred =  tokenizer_small.batch_decode(op,skip_special_tokens=True )[0]\n",
    "\n",
    "    print(f'-------{idx}------')\n",
    "    print(f'true : {target} \\npred : {text_pred}')\n",
    "    print('\\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
